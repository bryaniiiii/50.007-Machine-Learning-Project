{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k_final_layer\n",
      "[[[4, 'STOP', 0, -60.89565605907135], [4, 'STOP', 1, -61.11832757353623], [2, 'STOP', 0, -62.22106296329497], [2, 'STOP', 1, -62.44373447775985], [4, 'STOP', 2, -62.681561143781835]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8ba3d03cc0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;31m#output_prediction('CN/train', 'EN/dev.in', 'EN/dev.P4.out.top', 't:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;31m#output_prediction('CN/train', 'CN/dev.in', 'CN/dev.P4.out', 't:4')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m \u001b[0moutput_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EN/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EN/dev.in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EN/dev.P5.out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;31m#output_prediction('ES/train', 'ES/dev.in', 'ES/dev.P4.out', 't:4')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;31m#output_prediction('SG/train', 'SG/dev.in', 'SG/dev.P4.out', 't:4')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-8ba3d03cc0e4>\u001b[0m in \u001b[0;36moutput_prediction\u001b[0;34m(data_file_dir, devin_dir, devout_dir, algo)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'm'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi_topk_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtran_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_y_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-8ba3d03cc0e4>\u001b[0m in \u001b[0;36mviterbi_topk_weighted\u001b[0;34m(em, tran, x_test, select)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mys_final_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m#y_label_final_layer = max(set(ys_final_layer), key=ys_final_layer.count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0my_label_final_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_final_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mys1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_label_final_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m#to store the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.5/statistics.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \"\"\"\n\u001b[1;32m    468\u001b[0m     \u001b[0;31m# Generate a table of sorted (value, frequency) pairs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.5/statistics.py\u001b[0m in \u001b[0;36m_counts\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Generate a table of sorted (value, frequency) pairs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaojuan/anaconda/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "#Input: Directory of files (datafile_dir)\n",
    "#Output: X data set and Y data set (X,Y)\n",
    "import math\n",
    "#####################################################################\n",
    "def get_XY(datafile_dir):\n",
    "    f = open(datafile_dir, encoding = \"utf-8\")\n",
    "    f_content = f.read()\n",
    "    X = []\n",
    "    Y = []\n",
    "    xi = []\n",
    "    yi = []\n",
    "    \n",
    "    for data_pair in f_content.split('\\n'):\n",
    "        \n",
    "        if data_pair == '':\n",
    "            if xi != []:\n",
    "                X.append(xi)\n",
    "                Y.append(yi)\n",
    "                xi = []\n",
    "                yi = []\n",
    "            \n",
    "        else:\n",
    "            xij,yij = data_pair.split(\" \")\n",
    "            xi.append(xij)\n",
    "            yi.append(yij)\n",
    "            \n",
    "    return (X,Y)\n",
    "#####################################################################\n",
    "#Helper function: Get X sequence from a file\n",
    "#Input: Directory of a file (datafile_dir)\n",
    "#Output: Array of X sequences (X)\n",
    "def get_X(datafile_dir):\n",
    "    f = open(datafile_dir, encoding = \"utf-8\")\n",
    "    f_content = f.read()\n",
    "    X = []\n",
    "    xi = []\n",
    "    for data in f_content.split('\\n'):\n",
    "        \n",
    "        if data == '':\n",
    "            if (xi != []):\n",
    "                X.append(xi)\n",
    "                xi = []\n",
    "        else:\n",
    "            xij = data\n",
    "            xi.append(xij)\n",
    "    return X\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#Input: Dataset X and Y (X,Y)\n",
    "#Output: Emission parameters based on Dataset X and Y( em_dic, count_y_dic)\n",
    "def train_emission_param(data_file_dir):\n",
    "    X,Y =get_XY(data_file_dir)\n",
    "    o_unique = []\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    \n",
    "    for xi in X:\n",
    "        \n",
    "        for o in xi:\n",
    "            if o not in o_unique:\n",
    "                o_unique.append(o)\n",
    "   \n",
    "    count_y_dic = {'O':0, 'B-positive':0, 'I-positive':0,'B-negative':0,'I-negative':0,'B-neutral':0,'I-neutral':0}\n",
    "    count_x_y_dic = {}\n",
    "    em_dic = {}\n",
    "    for i in range(len(X)):\n",
    "        xi = X[i]\n",
    "        yi = Y[i]\n",
    "        \n",
    "        for j in range(len(xi)):\n",
    "            key = (xi[j],yi[j])\n",
    "            key_deno = yi[j]\n",
    "            origin = count_y_dic[key_deno] \n",
    "            count_y_dic[key_deno] = origin + 1\n",
    "            \n",
    "            if key not in count_x_y_dic:\n",
    "                count_x_y_dic[key] = 1\n",
    "            else:\n",
    "                value = count_x_y_dic[key]\n",
    "                count_x_y_dic[key] = value + 1\n",
    "   \n",
    "    for o in o_unique:\n",
    "        \n",
    "        for state in T:\n",
    "            key = (o,state)\n",
    "            if key not in count_x_y_dic:\n",
    "                em_dic[key] = 0\n",
    "            else:\n",
    "                em_dic[key] =float(count_x_y_dic[key])/float(count_y_dic[state]+1)\n",
    "    em_dic[1] = count_y_dic\n",
    "    return (em_dic)\n",
    "#train_emission_param('EN/train')\n",
    "        \n",
    "#####################################################################    \n",
    "#Part 2 2) Helper function to include non-appeared word in the test set\n",
    "#Input: emission parameters, and count of y , a new word\n",
    "#Output: updated emission parameters and count of y\n",
    "def get_default_parameter(em_dic):\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    default ={}\n",
    "    for state in T:\n",
    "        default[state] = 1/float(em_dic[1][state]+1)\n",
    "    return (default)\n",
    "\n",
    "\n",
    "       \n",
    "    \n",
    "#####################################################################        \n",
    "\n",
    "#Part 2 3)\n",
    "\n",
    "#Helper function: Get the optimal y labels for the x sequence\n",
    "#Input: evaluation file directory, and trained emission parameters\n",
    "#Output: predicted y sequence\n",
    "def get_y_predict(em_dic,x_test):\n",
    "    \n",
    "    y_predict = []\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    \n",
    "    for xm in x_test:\n",
    "        ym = []\n",
    "        \n",
    "        for xi in xm:\n",
    "            temp = 0\n",
    "            yi = 'I-negative'\n",
    "            \n",
    "            for state in T:\n",
    "                if (xi,state) not in em_dic:\n",
    "                    default = get_default_parameter(em_dic)\n",
    "                    if default[state]>=temp:\n",
    "                        temp=default[state]\n",
    "                        yi = state\n",
    "                else:\n",
    "                    if em_dic[(xi,state)] >= temp:\n",
    "                        temp = em_dic[(xi,state)]\n",
    "                        yi = state\n",
    "            #print (xi,yi)\n",
    "            ym.append(yi)\n",
    "        y_predict.append(ym) \n",
    "    return y_predict\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#Function: To write the predictions into a file \n",
    "#Input: data_file_dir,devout_dir,devin_dir\n",
    "def output_prediction(data_file_dir,devin_dir,devout_dir,algo):\n",
    "    x_test = get_X(devin_dir)\n",
    "    em_v = train_emission_param(data_file_dir)\n",
    "    tran_v = train_tran_param(data_file_dir)\n",
    "    if algo=='v':\n",
    "        y_predict = viterbi(em_v,tran_v,x_test)\n",
    "    elif  't' in algo:\n",
    "        select = int(algo.split(\":\")[1])\n",
    "        y_predict = viterbi_top(em_v,tran_v, x_test,select)\n",
    "    elif algo == 'p':\n",
    "        y_predict = perceptron_predict(data_file_dir,x_test)\n",
    "    elif 'm' in algo:\n",
    "        select = int(algo.split(\":\")[1])\n",
    "        y_predict = viterbi_topk_weighted(em_v,tran_v,x_test,select)\n",
    "    else:\n",
    "        y_predict = get_y_predict(em_v,x_test)\n",
    "    f_out = open(devout_dir,'w', encoding = \"utf-8\")\n",
    "    for i in range(len(x_test)):\n",
    "        xi = x_test[i] \n",
    "        yi = y_predict[i]\n",
    "        for j in range(len(xi)):\n",
    "            f_out.write(xi[j]+\" \"+yi[j]+\"\\n\")\n",
    "        f_out.write(' \\n')\n",
    "    f_out.close()\n",
    "\n",
    "\n",
    "#########################Testing PART 2############################################\n",
    "#output_prediction('SG/train','SG/dev.in','SG/dev.P2test.out','part2')        \n",
    "     \n",
    "######################### PART 3###########################################\n",
    "\n",
    "     \n",
    "def train_tran_param(data_file_dir):\n",
    "    X,Y = get_XY(data_file_dir)\n",
    "    tp_dic = {}\n",
    "    T = ['START','O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral','STOP']\n",
    "    count_y_dic = {'START':0,'O':0, 'B-positive':0, 'I-positive':0,'B-negative':0,'I-negative':0,'B-neutral':0,\n",
    "                   'I-neutral':0,'STOP':0}\n",
    "    count_yf_yt = {}\n",
    "    tp_dic = {}\n",
    "    for yi in Y:\n",
    "        count_y_dic['START'] +=1\n",
    "        yi1 = yi[0]\n",
    "        key =('START', yi1)\n",
    "        if key not in count_yf_yt:\n",
    "            count_yf_yt[('START',yi1)] = 1\n",
    "        else:\n",
    "            count_yf_yt[('START',yi1)] += 1\n",
    "        for f in range(1,len(yi)-1):\n",
    "            t = f + 1 \n",
    "            yf = yi[f]\n",
    "            yt = yi[t]\n",
    "            key = (yf,yt)\n",
    "            if key not in count_yf_yt:\n",
    "                count_yf_yt[key] = 1\n",
    "            else:\n",
    "                 count_yf_yt[key] = count_yf_yt[key] +1\n",
    "            if yf not in count_y_dic:\n",
    "                count_y_dic[yf] = 1\n",
    "            else:\n",
    "                count_y_dic[yf] +=1\n",
    "            if t == (len(yi)-1):\n",
    "                count_y_dic[yt] +=1\n",
    "                key = (yi[t],'STOP')\n",
    "                if key not in count_yf_yt:\n",
    "                    count_yf_yt[key] = 1\n",
    "                else:\n",
    "                    count_yf_yt[key] +=1\n",
    "                count_y_dic['STOP'] +=1\n",
    "         \n",
    "    for state_from in T[:8]:\n",
    "        for state_to in T[1:9]:\n",
    "            key = (state_from,state_to)\n",
    "            if key not in count_yf_yt:\n",
    "                tp_dic[key] = 0\n",
    "            else:\n",
    "                tp_dic[key] = float(count_yf_yt[key])/float(count_y_dic[state_from])\n",
    "         \n",
    "    return tp_dic\n",
    "\n",
    "\n",
    "######################### viterbi ###########################################\n",
    "def viterbi(em,tran,x_test):\n",
    "\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    y_predict =[]\n",
    "    for xm in x_test:\n",
    "        ym = []\n",
    "        #base case\n",
    "        temp = []\n",
    "        for state_first in range(len(T)):\n",
    "            key_em = (xm[0],T[state_first])\n",
    "            key_tra = ('START',T[state_first])\n",
    "            score =0\n",
    "            if key_em not in em : \n",
    "                default = get_default_parameter(em)\n",
    "                if tran[key_tra] != 0:\n",
    "                    score = math.log(1.0*default[T[state_first]]*tran[key_tra])\n",
    "                else:\n",
    "                    score = -1000000000\n",
    "            else :\n",
    "                if em[key_em] == 0 or tran[key_tra] == 0:\n",
    "                    score = -1000000000\n",
    "                else:\n",
    "                    score = math.log(1.0 * em[key_em]*tran[key_tra])\n",
    "            element_temp = ('START',state_first,score)\n",
    "            temp.append(element_temp)\n",
    "      \n",
    "        #moving forward recursivly\n",
    "        ym.append(temp)\n",
    "        temp = []\n",
    "        for i in range(len(xm)-1):\n",
    "            i=i+1\n",
    "            for state_to in range(len(T)):\n",
    "                max_score = -100000000000\n",
    "                max_state_from = 0\n",
    "                for state_from in range(len(T)):\n",
    "                    key_em = (xm[i],T[state_to])\n",
    "                    key_tra = (T[state_from],T[state_to])\n",
    "                   \n",
    "                    if key_em not in em:\n",
    "                        default = get_default_parameter(em)\n",
    "                        if tran[key_tra]!=0:\n",
    "                            score = float(ym[i-1][state_from][2])+math.log(float(default[T[state_to]]))+math.log(float(tran[key_tra]))\n",
    "                        else:\n",
    "                            score = -100000000\n",
    "                    else :\n",
    "                        if em[key_em] == 0 or tran[key_tra]==0:\n",
    "                            score = float(ym[i-1][state_from][2])+float(-10000000)\n",
    "                        else:\n",
    "                            score = float(ym[i-1][state_from][2])+math.log(float(em[key_em]))+math.log(float(tran[key_tra]))\n",
    "                    if score >=max_score:\n",
    "                        max_score = score\n",
    "                        max_state_from = state_from\n",
    "                element_temp = (max_state_from,state_to,max_score)\n",
    "                temp.append(element_temp)\n",
    "            ym.append(temp)\n",
    "\n",
    "            temp = []\n",
    "        # final case \n",
    "        max_score =-10000000000\n",
    "        max_state = 0\n",
    "        for state_from in range(len(T)):\n",
    "            final_layer = len(xm)\n",
    "            if tran[(T[state_from],'STOP')] != 0:\n",
    "                score = float(ym[final_layer-1][state_from][2])+ math.log(float(tran[(T[state_from],'STOP')]))\n",
    "            if score >= max_score:\n",
    "                max_score = score\n",
    "                max_state = state_from\n",
    "        key = (max_state,'STOP',max_score)\n",
    "        temp.append(key)\n",
    "        ym.append(temp)\n",
    "    \n",
    "        #backtracking \n",
    "        y1 = max_state\n",
    "        ym_predict_num =[]\n",
    "        for i in range(len(xm)-1,-1,-1):\n",
    "            y2 = y1\n",
    "            ym_predict_num.append(y2)\n",
    "            y1 = ym[i][y2][0]\n",
    "        ym_predict_lable =[]\n",
    "        t_dic ={0:'O', 1:'B-positive', 2:'I-positive',3:'B-negative',4:'I-negative',5:'B-neutral',6:'I-neutral'}\n",
    "        for i in range(len(ym_predict_num)-1,-1,-1):\n",
    "            y = t_dic[ym_predict_num[i]]\n",
    "            ym_predict_lable.append(y)\n",
    "        y_predict.append(ym_predict_lable)\n",
    "    return y_predict\n",
    "\n",
    "#########################Testing PART 3############################################\n",
    "\n",
    "#output_prediction('EN/train','EN/dev.in','EN/dev.P2.out','part2')\n",
    "#output_prediction('SG/train','SG/dev.in','SG/dev.P3.out','v') \n",
    "\n",
    "########################Part 4#####################################################\n",
    "\n",
    "from statistics import mode\n",
    "#Want to use a list(list(list(list())))\n",
    "def viterbi_topk_weighted(em,tran,x_test,select):\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    k = 5\n",
    "    y_predict =[]\n",
    "    for xm in x_test:\n",
    "        ym = []\n",
    "        \n",
    "        # Base case\n",
    "        temp = []\n",
    "        temp_final = []\n",
    "        for state_first in range(len(T)):\n",
    "            \n",
    "            key_em = (xm[0],T[state_first])\n",
    "            key_tra = ('START',T[state_first])\n",
    "            if key_em not in em : \n",
    "                default = get_default_parameter(em)\n",
    "                if tran[key_tra] != 0:\n",
    "                    score = math.log(1.0*default[T[state_first]]*tran[key_tra])\n",
    "                else:\n",
    "                    score = -1000000000\n",
    "            else :\n",
    "                if em[key_em] == 0 or tran[key_tra] == 0:\n",
    "                    score = -1000000000\n",
    "                else:\n",
    "                    score = math.log(1.0 * em[key_em]*tran[key_tra])\n",
    "            node = ['START',state_first,0,score]\n",
    "          \n",
    "            temp.append(node)\n",
    "            temp_final.append(temp)\n",
    "            temp = []\n",
    "        \n",
    "      \n",
    "        # Moving forward recursivly\n",
    "        ym.append(temp_final)\n",
    "        #print('')\n",
    "        temp = []\n",
    "        \n",
    "       \n",
    "                \n",
    "            \n",
    "        for i in range(len(xm)-1):\n",
    "            i=i+1\n",
    "            #every node in current layer\n",
    "            for state_to in range(len(T)):\n",
    "                paths = []\n",
    "                score_list =[]\n",
    "                #every node in previous layer\n",
    "                for state_from in range(len(T)):\n",
    "                    key_em = (xm[i],T[state_to])\n",
    "                    key_tra = (T[state_from],T[state_to])\n",
    "                    if len(ym[i-1][state_from])==1:\n",
    "                        if key_em not in em:\n",
    "                            default = get_default_parameter(em)\n",
    "                            if tran[key_tra]!=0:\n",
    "                                score = float(ym[i-1][state_from][0][3])+math.log(float(default[T[state_to]]))+math.log(float(tran[key_tra]))\n",
    "                            else:\n",
    "                                score = -100000000\n",
    "                        else :\n",
    "                            if em[key_em] == 0 or tran[key_tra]==0:\n",
    "                                score = float(ym[i-1][state_from][0][3])+float(-10000000)\n",
    "                            else:\n",
    "                                score = float(ym[i-1][state_from][0][3])+math.log(float(em[key_em]))+math.log(float(tran[key_tra]))  \n",
    "          \n",
    "                        paths.append([state_from,state_to,0,score])\n",
    "                        \n",
    "                    else:    \n",
    "                        \n",
    "                        for e in range(len(ym[i-1][state_from])):\n",
    "                        \n",
    "                            if key_em not in em:\n",
    "                                default = get_default_parameter(em)\n",
    "                                if tran[key_tra]!=0:\n",
    "                                    score = float(ym[i-1][state_from][e][3])+math.log(float(default[T[state_to]]))+math.log(float(tran[key_tra]))\n",
    "                                else:\n",
    "                                    score = -100000000\n",
    "                            else:\n",
    "                                if em[key_em] == 0 or tran[key_tra]==0:\n",
    "                                    score = float(ym[i-1][state_from][e][3])+float(-10000000)\n",
    "                                else:\n",
    "                                    score = float(ym[i-1][state_from][e][3])+math.log(float(em[key_em]))+math.log(float(tran[key_tra]))  \n",
    "                            paths.append([state_from, state_to, e, score])\n",
    "                #sort top 5\n",
    "                top_five = sorted(paths, key=lambda top_five:top_five[3], reverse=True)[:5]\n",
    "                temp.append(top_five)\n",
    "                \n",
    "            ym.append(temp)\n",
    "            temp = []\n",
    " \n",
    "        # Final case \n",
    "        temp =[]\n",
    "        paths = []\n",
    "        top_five = []\n",
    "        for state_from in range(len(T)):\n",
    "            for e in range(k):\n",
    "                final_layer = len(xm)\n",
    "                if tran[(T[state_from],'STOP')] != 0:\n",
    "                    if final_layer==1:\n",
    "                         score = float(ym[final_layer-1][state_from][0][3])+ math.log(float(tran[(T[state_from],'STOP')]))\n",
    "                    else:\n",
    "                         score = float(ym[final_layer-1][state_from][e][3])+ math.log(float(tran[(T[state_from],'STOP')]))\n",
    "            #store the top 5\n",
    "                paths.append([state_from, 'STOP', e, score])\n",
    "        \n",
    "        #sort top 5\n",
    "        top_five = sorted(paths, key=lambda top_five: top_five[3], reverse=True)[:5]\n",
    "\n",
    "        \n",
    "        temp.append(top_five)\n",
    "        ym.append(temp)\n",
    "        ####### Backtracking ##########################################\n",
    "        weights =[]\n",
    "        for j in range(k):\n",
    "            a = 100\n",
    "            weights.append(a)\n",
    "            a-=3\n",
    "            \n",
    "        final_layer = len(xm)\n",
    "        top_k_final_layer = ym[final_layer]\n",
    "        print ('top_k_final_layer')\n",
    "        print (top_k_final_layer)\n",
    "        ys_final_layer = []\n",
    "        for i in range(k):\n",
    "            state_from = top_k_final_layer[0][i]\n",
    "            temp = state_from*weights[i]\n",
    "            ys_final_layer.append(temp)\n",
    "        #y_label_final_layer = max(set(ys_final_layer), key=ys_final_layer.count)\n",
    "        y_label_final_layer = mode(ys_final_layer)\n",
    "        ys1 = ym[final_layer-1][y_label_final_layer]  \n",
    "        #to store the path \n",
    "        ym_predict_num =[]\n",
    "        ym_predict_num.append(ys1)\n",
    "        \n",
    "        for i in range(len(xm)-1,-1,-1):\n",
    "            ys_current_node =[]\n",
    "            for j in range(len(k)):\n",
    "                state_from = ys1[j]\n",
    "                temp = state_from*weights[j]\n",
    "                ys_current_node.append(temp)\n",
    "            y_label = max(set(ys_current_node), key=ys_current_node.count)\n",
    "            ym_predict_num.append(y_label)\n",
    "            ys1 = ym[i-1][y_label]\n",
    "        \n",
    "        ym_predict_label =[]\n",
    "        t_dic ={0:'O', 1:'B-positive', 2:'I-positive',3:'B-negative',4:'I-negative',5:'B-neutral',6:'I-neutral'}\n",
    "        # start at the end of the collected nodes. Counting down to -1\n",
    "        for i in range(len(ym_predict_num)-1,-1,-1):\n",
    "            #take the label corresponding to the node\n",
    "            y = t_dic[ym_predict_num[i]]\n",
    "            ym_predict_label.append(y)\n",
    "        y_predict.append(ym_predict_label)\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "#################Test part 4#########################\n",
    "#train_tran_param('EN/train') \n",
    "#viterbi_top('EN/train','EN/dev.in') \n",
    "#output_prediction('SG/train','SG/dev.in','EN/dev.P2.out','part2')\n",
    "#output_prediction('SG/train','SG/dev.in','SG/dev.P3.out','v') \n",
    "#output_prediction('CN/train', 'EN/dev.in', 'EN/dev.P4.out.top', 't:0')\n",
    "#output_prediction('CN/train', 'CN/dev.in', 'CN/dev.P4.out', 't:4')\n",
    "output_prediction('EN/train', 'EN/dev.in', 'EN/dev.P5.out', 'm:0')\n",
    "#output_prediction('ES/train', 'ES/dev.in', 'ES/dev.P4.out', 't:4')\n",
    "#output_prediction('SG/train', 'SG/dev.in', 'SG/dev.P4.out', 't:4')\n",
    "\n",
    "\n",
    "############################  PART 5 #################################\n",
    "#Helper function: get count_yf_yt\n",
    "def get_tran_count(Y):\n",
    "    count_yf_yt = {}\n",
    "    T = ['START','O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral','STOP']\n",
    "    for yi in Y:\n",
    "        yi1 = yi[0]\n",
    "        key =('START', yi1)\n",
    "        if key not in count_yf_yt:\n",
    "            count_yf_yt[('START',yi1)] = 1\n",
    "        else:\n",
    "            count_yf_yt[('START',yi1)] += 1\n",
    "        for f in range(len(yi)-1):\n",
    "            t = f + 1 \n",
    "            yf = yi[f]\n",
    "            yt = yi[t]\n",
    "            key = (yf,yt)\n",
    "            if key not in count_yf_yt:\n",
    "                count_yf_yt[key] = 1\n",
    "            else:\n",
    "                 count_yf_yt[key] = count_yf_yt[key] +1\n",
    "            if t == len(yi):\n",
    "                key = (yi[t],'STOP')\n",
    "                if key not in count_yf_yt:\n",
    "                    count_yf_yt[key] = 1\n",
    "                else:\n",
    "                    count_yf_yt[key] +=1\n",
    "    for state_from in T[:8]:\n",
    "        for state_to in T[1:9]:\n",
    "            key = (state_from,state_to)\n",
    "            if key not in count_yf_yt:\n",
    "                count_yf_yt[key] = 0\n",
    "        \n",
    "        \n",
    "    return count_yf_yt\n",
    "#############################################################\n",
    "#Helper function: get count_y_x\n",
    "def get_em_count(X,Y):\n",
    "    o_unique = []\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    em_dic ={}\n",
    "    for xi in X:\n",
    "        \n",
    "        for o in xi:\n",
    "            if o not in o_unique:\n",
    "                o_unique.append(o)\n",
    "    count_x_y_dic = {}\n",
    "    for i in range(len(X)):\n",
    "        xi = X[i]\n",
    "        yi = Y[i]\n",
    "        \n",
    "        for j in range(len(xi)):\n",
    "            key = (xi[j],yi[j])\n",
    "            key_deno = yi[j] \n",
    "            if key not in count_x_y_dic:\n",
    "                count_x_y_dic[key] = 1\n",
    "            else:\n",
    "                value = count_x_y_dic[key]\n",
    "                count_x_y_dic[key] = value + 1\n",
    "    for o in o_unique:\n",
    "        \n",
    "        for state in T:\n",
    "            key = (o,state)\n",
    "            if key not in count_x_y_dic:\n",
    "                count_x_y_dic[key] = 0\n",
    "    return count_x_y_dic\n",
    "   \n",
    "######################################################################\n",
    "def get_count_y(Y):\n",
    "    count_y_dic = {'START':0,'O':0, 'B-positive':0, 'I-positive':0,'B-negative':0,'I-negative':0,'B-neutral':0,\n",
    "                   'I-neutral':0,'STOP':0}\n",
    "    for ym in Y:\n",
    "        for yi in ym:\n",
    "            count_y_dic[yi] +=1\n",
    "    return count_y_dic\n",
    "\n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
