{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)]]\n",
      "1\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)]]\n",
      "2\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)]]\n",
      "3\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 3.812232670001486e-09), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)]]\n",
      "4\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 3.812232670001486e-09), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 5.223454367230643e-12), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (0, 5, 1.4347774987358586e-12), (6, 6, 0.0)]]\n",
      "5\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 3.812232670001486e-09), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 5.223454367230643e-12), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (0, 5, 1.4347774987358586e-12), (6, 6, 0.0)], [(0, 0, 2.752725228774002e-16), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)]]\n",
      "6\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 3.812232670001486e-09), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 5.223454367230643e-12), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (0, 5, 1.4347774987358586e-12), (6, 6, 0.0)], [(0, 0, 2.752725228774002e-16), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 1.4506676334087128e-20), (0, 1, 1.3914716776872213e-20), (6, 2, 0.0), (0, 3, 1.2998762031055694e-20), (6, 4, 0.0), (0, 5, 1.2950246483925641e-20), (6, 6, 0.0)]]\n",
      "7\n",
      "[[('START', 0, 0.0010791508847994738), ('START', 1, 0.0), ('START', 2, 0), ('START', 3, 0.0), ('START', 4, 0), ('START', 5, 0.0013886549236459516), ('START', 6, 0.0)], [(0, 0, 1.706115718102605e-07), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 3.812232670001486e-09), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 5.223454367230643e-12), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (0, 5, 1.4347774987358586e-12), (6, 6, 0.0)], [(0, 0, 2.752725228774002e-16), (6, 1, 0.0), (6, 2, 0.0), (6, 3, 0.0), (6, 4, 0.0), (6, 5, 0.0), (6, 6, 0.0)], [(0, 0, 1.4506676334087128e-20), (0, 1, 1.3914716776872213e-20), (6, 2, 0.0), (0, 3, 1.2998762031055694e-20), (6, 4, 0.0), (0, 5, 1.2950246483925641e-20), (6, 6, 0.0)], [(0, 0, 7.644920606757768e-25), (0, 1, 7.332961911802553e-25), (1, 2, 2.711602387790896e-23), (0, 3, 6.85025993721611e-25), (3, 4, 9.188780056435921e-23), (0, 5, 6.82469257102823e-25), (5, 6, 8.196879327010516e-24)]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-d5336e8dca07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;31m#########################Testing PART 3############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;31m#train_tran_param('EN/train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EN/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EN/dev.in'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-109-d5336e8dca07>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(data_file_dir, test_data_dir)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mym_predict_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mym_predict_lable\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mt_dic\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'B-positive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'I-positive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'B-negative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'I-negative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'B-neutral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'I-neutral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Part 2 \n",
    "#(1) Write a function to evaluate the emission parameters based on data set X and Y\n",
    "\n",
    "#Input: Directory of files (datafile_dir)\n",
    "#Output: X data set and Y data set (X,Y)\n",
    "#####################################################################\n",
    "def get_XY(datafile_dir):\n",
    "    f = open(datafile_dir)\n",
    "    f_content = f.read()\n",
    "    X = []\n",
    "    Y = []\n",
    "    xi = []\n",
    "    yi = []\n",
    "    \n",
    "    for data_pair in f_content.split('\\n'):\n",
    "        \n",
    "        if data_pair == '':\n",
    "            if xi != []:\n",
    "                X.append(xi)\n",
    "                Y.append(yi)\n",
    "                xi = []\n",
    "                yi = []\n",
    "            \n",
    "        else:\n",
    "            xij,yij = data_pair.split(\" \")\n",
    "            xi.append(xij)\n",
    "            yi.append(yij)\n",
    "            \n",
    "    return (X,Y)\n",
    "#####################################################################\n",
    "#Helper function: Get X sequence from a file\n",
    "#Input: Directory of a file (datafile_dir)\n",
    "#Output: Array of X sequences (X)\n",
    "def get_X(datafile_dir):\n",
    "    f = open(datafile_dir)\n",
    "    f_content = f.read()\n",
    "    X = []\n",
    "    xi = []\n",
    "    for data in f_content.split('\\n'):\n",
    "        \n",
    "        if data == '':\n",
    "            if (xi != []):\n",
    "                X.append(xi)\n",
    "                xi = []\n",
    "        else:\n",
    "            xij = data\n",
    "            xi.append(xij)\n",
    "    return X\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#Input: Dataset X and Y (X,Y)\n",
    "#Output: Emission parameters based on Dataset X and Y( em_dic, count_y_dic)\n",
    "def train_emission_param(data_file_dir):\n",
    "    X,Y =get_XY(data_file_dir)\n",
    "    o_unique = []\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    \n",
    "    for xi in X:\n",
    "        \n",
    "        for o in xi:\n",
    "            if o not in o_unique:\n",
    "                o_unique.append(o)\n",
    "        \n",
    "    #print (o_unique)\n",
    "    count_y_dic = {'O':0, 'B-positive':0, 'I-positive':0,'B-negative':0,'I-negative':0,'B-neutral':0,'I-neutral':0}\n",
    "    count_x_y_dic = {}\n",
    "    em_dic = {}\n",
    "    for i in range(len(X)):\n",
    "        xi = X[i]\n",
    "        yi = Y[i]\n",
    "        \n",
    "        for j in range(len(xi)):\n",
    "            key = (xi[j],yi[j])\n",
    "            key_deno = yi[j]\n",
    "            origin = count_y_dic[key_deno] \n",
    "            count_y_dic[key_deno] = origin + 1\n",
    "            \n",
    "            if key not in count_x_y_dic:\n",
    "                count_x_y_dic[key] = 1\n",
    "            else:\n",
    "                value = count_x_y_dic[key]\n",
    "                count_x_y_dic[key] = value + 1\n",
    "   \n",
    "    for o in o_unique:\n",
    "        \n",
    "        for state in T:\n",
    "            key = (o,state)\n",
    "            if key not in count_x_y_dic:\n",
    "                em_dic[key] = 0 #Fix the problem where the word doesn't have certain states\n",
    "            else:\n",
    "                em_dic[key] =float(count_x_y_dic[key])/float(count_y_dic[state])\n",
    "            #print (key, em_dic[key])\n",
    "        em_dic[1] = count_y_dic\n",
    "    return (em_dic)\n",
    "        \n",
    "#####################################################################    \n",
    "#Part 2 2) Helper function to include non-appeared word in the test set\n",
    "#Input: emission parameters, and count of y , a new word\n",
    "#Output: updated emission parameters and count of y\n",
    "def get_default_parameter(em_dic,xi):\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    default ={}\n",
    "    for state in T:\n",
    "        key = (xi,state)\n",
    "        default[state] = 1/float(em_dic[1][state])\n",
    "    return (default)\n",
    "       \n",
    "    \n",
    "#####################################################################        \n",
    "\n",
    "#Part 2 3)\n",
    "\n",
    "#Helper function: Get the optimal y labels for the x sequence\n",
    "#Input: evaluation file directory, and trained emission parameters\n",
    "#Output: predicted y sequence\n",
    "def get_y_predict(em_dic,count_y_predict,x_test):\n",
    "    \n",
    "    y_predict = []\n",
    "    T = ['O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral']\n",
    "    \n",
    "    for xm in x_test:\n",
    "        ym = []\n",
    "        \n",
    "        for xi in xm:\n",
    "            temp = 0\n",
    "            yi = 'O'\n",
    "            \n",
    "            if (xi,'O') not in em_dic:\n",
    "                em_dic,count_y_predict = set_default_parameter(em_dic,count_y_predict,xi)\n",
    "            \n",
    "            for state in T:\n",
    "                if em_dic[xi,state] >= temp:\n",
    "                    temp = em_dic[xi,state]\n",
    "                    yi = state\n",
    "            #print (xi,yi)\n",
    "            ym.append(yi)\n",
    "        y_predict.append(ym) \n",
    "    return y_predict\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#Function: To write the predictions into a file \n",
    "#Input: data_file_dir,devout_dir,devin_dir\n",
    "def output_prediction(data_file_dir,devin_dir,devout_dir):\n",
    "    X,Y = get_XY(data_file_dir)\n",
    "    em_dic,count_y_predict = train_emission_param(X,Y)\n",
    "    x_test = get_X(devin_dir)\n",
    "    y_predict = get_y_predict(em_dic,count_y_predict,x_test)\n",
    "    f_out = open(devout_dir,'w')\n",
    "    for i in range(len(x_test)):\n",
    "        xi = x_test[i] \n",
    "        yi = y_predict[i]\n",
    "        f_out.write('\\n')\n",
    "        for j in range(len(xi)):\n",
    "            f_out.write(xi[j]+\" \"+yi[j]+\"\\n\")\n",
    "    f_out.close()\n",
    "\n",
    "############################################################################    \n",
    "def get_predicted_entities(x_test,y_predict):\n",
    "    entity_list =[]\n",
    "    for k in range(len(y_predict)):\n",
    "        ym = y_predict[k]\n",
    "        entity_sublist = []\n",
    "        entity = ''\n",
    "        flag = 0\n",
    "        sentiment = 'O' \n",
    "        for i in range(len(ym)):\n",
    "            \n",
    "            if ym[i] == 'O':\n",
    "                yi = ym[i]\n",
    "            elif ym[i] != 'O':\n",
    "                yi = ym[i].split('-')[1]\n",
    "            \n",
    "            if yi != 'O' and yi != sentiment:\n",
    "                if sentiment != 'O':\n",
    "                    element = (entity,sentiment)\n",
    "                    entity_sublist.append(element)\n",
    "                entity = x_test[k][i]\n",
    "                sentiment = yi\n",
    "                flag = 1 \n",
    "            elif yi != 'O' and flag == 1 and yi == sentiment:\n",
    "                entity = entity + ' ' + x_test[k][i]\n",
    "            elif yi == 'O' and flag == 1:\n",
    "                element = (entity,sentiment)\n",
    "                entity_sublist.append(element)\n",
    "                flag = 0\n",
    "                sentiment = 'O'\n",
    "        if(entity_sublist != []):\n",
    "            entity_list.append(entity_sublist)\n",
    "    print (entity_list)\n",
    "    return entity_list\n",
    "\n",
    "############################################################################       \n",
    "def get_gold_entities(devout_dir):  \n",
    "    X_gold,Y_gold = get_XY(devout_dir)\n",
    "    gold_entity_list = []\n",
    "    for k in range(len(Y_gold)):\n",
    "        ym = Y_gold[k]\n",
    "        gold_entity_sublist = []\n",
    "        entity = ''\n",
    "        flag = 0\n",
    "        sentiment = 'O'\n",
    "        for i in range(len(ym)):\n",
    "            yi = ym[i]\n",
    "            if yi == 'B-neutral' or yi == 'B-negative' or yi == 'B-positive':\n",
    "                entity = X_gold[k][i]\n",
    "                sentiment = yi.split('-')[1]\n",
    "                flag = 1 \n",
    "            elif yi == 'O' and flag ==1:\n",
    "                element = (entity,sentiment)\n",
    "                gold_entity_sublist.append(element)\n",
    "                flag = 0\n",
    "            elif flag == 1 and yi !='O':\n",
    "                entity = entity + ' '+ X_gold[k][i]\n",
    "        if(gold_entity_sublist != []):\n",
    "            gold_entity_list.append(gold_entity_sublist)\n",
    "   \n",
    "    print ('gold_entity_list:\\n',gold_entity_list)\n",
    "    return gold_entity_list\n",
    "    \n",
    "\n",
    "\n",
    "#########################Testing PART 2############################################\n",
    "#output_prediction('SG/train','SG/dev.in','SG/dev.P2.out')        \n",
    "     \n",
    "######################### PART 3###########################################\n",
    "\n",
    "     \n",
    "def train_tran_param(data_file_dir):\n",
    "    X,Y = get_XY(data_file_dir)\n",
    "    tp_dic = {}\n",
    "    T = ['START','O', 'B-positive', 'I-positive','B-negative','I-negative','B-neutral','I-neutral','STOP']\n",
    "    count_y_dic = {'START':0,'O':0, 'B-positive':0, 'I-positive':0,'B-negative':0,'I-negative':0,'B-neutral':0,\n",
    "                   'I-neutral':0,'STOP':0}\n",
    "    count_yf_yt = {}\n",
    "    tp_dic = {}\n",
    "    for yi in Y:\n",
    "        count_y_dic['START'] +=1\n",
    "        yi1 = yi[0]\n",
    "        key =('START', yi1)\n",
    "        if key not in count_yf_yt:\n",
    "            count_yf_yt[('START',yi1)] = 1\n",
    "        else:\n",
    "            count_yf_yt[('START',yi1)] += 1\n",
    "        for f in range(len(yi)-1):\n",
    "            t = f + 1 \n",
    "            yf = yi[f]\n",
    "            yt = yi[t]\n",
    "            key = (yf,yt)\n",
    "            if key not in count_yf_yt:\n",
    "                count_yf_yt[key] = 1\n",
    "            else:\n",
    "                 count_yf_yt[key] = count_yf_yt[key] +1\n",
    "            if yf not in count_y_dic:\n",
    "                count_y_dic[yf] = 1\n",
    "            else:\n",
    "                count_y_dic[yf] +=1\n",
    "            if t == len(yi):\n",
    "                key = (yi[t],'STOP')\n",
    "                if key not in count_yf_yt:\n",
    "                    count_yf_yt[key] = 1\n",
    "                else:\n",
    "                    count_yf_yt[key] +=1\n",
    "        count_y_dic['STOP'] +=1\n",
    "         \n",
    "    for state_from in T[:8]:\n",
    "        for state_to in T[1:9]:\n",
    "            key = (state_from,state_to)\n",
    "            if key not in count_yf_yt:\n",
    "                tp_dic[key] = 0\n",
    "            else:\n",
    "                tp_dic[key] = count_yf_yt[key]/count_y_dic[state_from]\n",
    "    \n",
    "    return tp_dic\n",
    "\n",
    "######################### viterbi ###########################################\n",
    "\n",
    "\n",
    "#########################Testing PART 3############################################\n",
    "#train_tran_param('EN/train') \n",
    "viterbi('EN/train','EN/dev.in')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,0,-1):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
